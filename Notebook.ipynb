{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy-based model\n",
    "Energy-based models associate a scalar energy to each configuration of the variables of interest. Low energy is more desirable. The probability distribution based on an energy function can be defined as follows\n",
    "$$ \\Pr(x) = \\frac{\\exp (-E(x))}{Z}\\,,$$\n",
    "where $Z = \\sum_{x} \\exp (-E(x))$ denotes the normalization factor or **partition function**. \n",
    "\n",
    "### Restricted Boltzmann Machine\n",
    "\n",
    "Restricted Boltzmann Machine (RBM) has an efficient training algorithm. In order to increase the expressive power of the model, we do not observe the example $x$ fully, we also want to introduce some non-observed variables.  Consider an observed part $x$ and a hidden part $h$. We can then write:\n",
    "$$\\Pr(x) = \\sum_h \\frac{\\exp (-E(x, h))}{Z} \\,.$$\n",
    "\n",
    "In RBM, the energy function is defined as\n",
    "$$\n",
    "E(x, h) = -a^\\top x - b^\\top h - x^\\top W h \\,.\n",
    "$$\n",
    "\n",
    "To make RBM as an energy-based model, the free energy function is computed as follows\n",
    "$$\n",
    "\\begin{align}\n",
    "F(x) &= -\\log \\sum_h \\exp (-E(x, h)) \\\\\n",
    "     &= -a^\\top x - \\sum_j \\log (1 + \\exp(W^{\\top}_jx + b_j))\\,.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We have an tractable expression for the conditional probabilities\n",
    "$$\n",
    "\\Pr (h|x) = \\prod_i \\Pr (h_i | x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['SHELL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from rbm import RBM\n",
    "import libs\n",
    "from libs import train, show_and_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # batch size\n",
    "n_epochs = 12 # number of epochs\n",
    "lr = 0.001 # learning rate\n",
    "n_hid = 128 # number of neurons in the hidden layer\n",
    "n_vis = 784 # input size\n",
    "k = 1 # number of contrastive divergence steps during training\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a RBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Restricted Boltzmann Machine\n",
    "model = RBM(n_vis=n_vis, n_hid=n_hid, k=k).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./output', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if device == \"cuda\" else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [00:22<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epoch_loss)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/pgm/rbm-pytorch/libs.py:48\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, device, n_epochs, lr, k)\u001b[0m\n\u001b[1;32m     46\u001b[0m v, v_gibbs \u001b[38;5;241m=\u001b[39m model(data\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m784\u001b[39m), k)\n\u001b[1;32m     47\u001b[0m loss \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfree_energy(v) \u001b[38;5;241m-\u001b[39m model\u001b[38;5;241m.\u001b[39mfree_energy(v_gibbs)\n\u001b[0;32m---> 48\u001b[0m \u001b[43mloss_\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     49\u001b[0m train_op\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     50\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_loss = train(model, train_loader, device, n_epochs=n_epochs, lr=lr)\n",
    "\n",
    "plt.plot(epoch_loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'Training Loss (n_hid={n_hid}, n_epochs={n_epochs}, lr={lr}, k={k})')\n",
    "custom_path = f'rbm_{n_hid}_{n_epochs}_{lr}_{k}'\n",
    "plt.savefig('plots/' + custom_path + '.png')\n",
    "plt.close()\n",
    "\n",
    "filepath = 'weights/'\n",
    "filepath += custom_path + '.pt'\n",
    "torch.save(model.state_dict(), filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can do inpainting using the saved weights. We can treat this task as conditioned generation. At every step of gibbs sampling in the CD-k algo, we can convert the observed pixels back to their true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filepath' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 19\u001b[0m\n\u001b[1;32m     10\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(\n\u001b[1;32m     11\u001b[0m     datasets\u001b[38;5;241m.\u001b[39mMNIST(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./output\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     12\u001b[0m                    transform\u001b[38;5;241m=\u001b[39mtransforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m model \u001b[38;5;241m=\u001b[39m RBM(n_vis\u001b[38;5;241m=\u001b[39mn_vis, n_hid\u001b[38;5;241m=\u001b[39mn_hid, k\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m---> 19\u001b[0m model\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[43mfilepath\u001b[49m))\n\u001b[1;32m     20\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'filepath' is not defined"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # batch size\n",
    "n_hid = 128 # number of neurons in the hidden layer\n",
    "n_vis = 784 # input size\n",
    "k = 1000 # number of contrastive divergence steps during inference\n",
    "\n",
    "# this will correspond to the test set where the only the top half of the image\n",
    "# is observed and the task is to predict the bottom half of the image\n",
    "# since this is grayscale, we will be using accuracy as the metric\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./output', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "model = RBM(n_vis=n_vis, n_hid=n_hid, k=k)\n",
    "model.load_state_dict(torch.load(filepath))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can play around with this k during test time\n",
    "reload(libs)\n",
    "acc = libs.test_for_inpaint(model, test_loader, device, random_values=True,k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(libs)\n",
    "acc = libs.test_for_inpaint(model, test_loader, device, random_values=False,k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(libs)\n",
    "# print('1', torch.cuda.memory_summary())\n",
    "torch.cuda.empty_cache()\n",
    "# print('2', torch.cuda.memory_summary())\n",
    "acc = libs.test_for_inpaint(model, test_loader, device, random_values=True,k=50000, plot=True)\n",
    "acc = libs.test_for_inpaint(model, test_loader, device, random_values=False,k=1000, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the rest of the stuff below for now :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = next(iter(train_loader))[0]\n",
    "v, v_gibbs = model(images.view(-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the real images\n",
    "show_and_save(make_grid(v.view(batch_size, 1, 28, 28).data), 'output/real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the generated images\n",
    "show_and_save(make_grid(v_gibbs.view(batch_size, 1, 28, 28).data), 'output/fake')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How one image is factorized through the hidden variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 4\n",
    "kth = 18\n",
    "d = images[kth:kth+1]\n",
    "\n",
    "V = torch.sigmoid(F.linear(d.view(1, -1), model.W, model.h))\n",
    "v, o = torch.sort(V.view(-1))\n",
    "\n",
    "fig, ax = plt.subplots(1, n_sample + 1, figsize=(3*(1 + n_sample),3))\n",
    "ax[0].imshow(d.view(28, 28).numpy(), cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "\n",
    "for k, i in enumerate(o[-n_sample:].numpy()):\n",
    "    f = model.W[i].view(28, 28).data.numpy()\n",
    "    ax[k + 1].imshow(f, cmap='gray')\n",
    "    ax[k + 1].set_title('p=%.2f'% V[0][i].item())\n",
    "    \n",
    "plt.savefig('output/factor.png', dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
