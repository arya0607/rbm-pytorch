{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restricted Boltzmann Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy-based model\n",
    "Energy-based models associate a scalar energy to each configuration of the variables of interest. Low energy is more desirable. The probability distribution based on an energy function can be defined as follows\n",
    "$$ \\Pr(x) = \\frac{\\exp (-E(x))}{Z}\\,,$$\n",
    "where $Z = \\sum_{x} \\exp (-E(x))$ denotes the normalization factor or **partition function**. \n",
    "\n",
    "### Restricted Boltzmann Machine\n",
    "\n",
    "Restricted Boltzmann Machine (RBM) has an efficient training algorithm. In order to increase the expressive power of the model, we do not observe the example $x$ fully, we also want to introduce some non-observed variables.  Consider an observed part $x$ and a hidden part $h$. We can then write:\n",
    "$$\\Pr(x) = \\sum_h \\frac{\\exp (-E(x, h))}{Z} \\,.$$\n",
    "\n",
    "In RBM, the energy function is defined as\n",
    "$$\n",
    "E(x, h) = -a^\\top x - b^\\top h - x^\\top W h \\,.\n",
    "$$\n",
    "\n",
    "To make RBM as an energy-based model, the free energy function is computed as follows\n",
    "$$\n",
    "\\begin{align}\n",
    "F(x) &= -\\log \\sum_h \\exp (-E(x, h)) \\\\\n",
    "     &= -a^\\top x - \\sum_j \\log (1 + \\exp(W^{\\top}_jx + b_j))\\,.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "We have an tractable expression for the conditional probabilities\n",
    "$$\n",
    "\\Pr (h|x) = \\prod_i \\Pr (h_i | x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.environ['SHELL'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from rbm import RBM\n",
    "import libs\n",
    "from libs import train, show_and_save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make some configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 # batch size\n",
    "n_epochs = 12 # number of epochs\n",
    "lr = 0.001 # learning rate\n",
    "n_hid = 128 # number of neurons in the hidden layer\n",
    "n_vis = 784 # input size\n",
    "k = 1 # number of contrastive divergence steps during training\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a RBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Restricted Boltzmann Machine\n",
    "model = RBM(n_vis=n_vis, n_hid=n_hid, k=k).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./output', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=4,\n",
    "    pin_memory=True if device == \"cuda\" else False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12 [02:57<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m epoch_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(epoch_loss)\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/pgm/rbm-pytorch/libs.py:50\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, device, n_epochs, lr, k)\u001b[0m\n\u001b[1;32m     48\u001b[0m     loss_\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m     49\u001b[0m     train_op\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 50\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     train_op\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     52\u001b[0m epoch_loss\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mmean(loss_))\n",
      "File \u001b[0;32m~/miniconda3/envs/vlrhw1/lib/python3.8/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    490\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/vlrhw1/lib/python3.8/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_loss = train(model, train_loader, device, n_epochs=n_epochs, lr=lr)\n",
    "\n",
    "plt.plot(epoch_loss)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title(f'Training Loss (n_hid={n_hid}, n_epochs={n_epochs}, lr={lr}, k={k})')\n",
    "custom_path = f'rbm_{n_hid}_{n_epochs}_{lr}_{k}'\n",
    "plt.savefig('plots/' + custom_path + '.png')\n",
    "plt.close()\n",
    "\n",
    "filepath = 'weights/'\n",
    "filepath += custom_path + '.pt'\n",
    "torch.save(model.state_dict(), filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can do inpainting using the saved weights. We can treat this task as conditioned generation. At every step of gibbs sampling in the CD-k algo, we can convert the observed pixels back to their true values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RBM()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 64 # batch size\n",
    "n_hid = 128 # number of neurons in the hidden layer\n",
    "n_vis = 784 # input size\n",
    "k = 1000 # number of contrastive divergence steps during inference\n",
    "\n",
    "# this will correspond to the test set where the only the top half of the image\n",
    "# is observed and the task is to predict the bottom half of the image\n",
    "# since this is grayscale, we will be using accuracy as the metric\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('./output', train=False, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor()\n",
    "                   ])),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "model = RBM(n_vis=n_vis, n_hid=n_hid, k=k)\n",
    "model.load_state_dict(torch.load(filepath))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the RBM model for inpainting...\n",
      "Random Values: True k: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:32,  4.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 3075741 total: 3920000\n",
      "Final Accuracy: 78.46%\n",
      "Accuracy: 0.78%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# can play around with this k during test time\n",
    "reload(libs)\n",
    "acc = libs.test_for_inpaint(model, test_loader, device, random_values=True,k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing the RBM model for inpainting...\n",
      "Random Values: False ; k: 1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "157it [00:34,  4.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct: 3074863 total: 3920000\n",
      "Final Accuracy: 78.44%\n"
     ]
    }
   ],
   "source": [
    "reload(libs)\n",
    "acc = libs.test_for_inpaint(model, test_loader, device, random_values=False,k=k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ignore the rest of the stuff below for now :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = next(iter(train_loader))[0]\n",
    "v, v_gibbs = model(images.view(-1, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the real images\n",
    "show_and_save(make_grid(v.view(batch_size, 1, 28, 28).data), 'output/real')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the generated images\n",
    "show_and_save(make_grid(v_gibbs.view(batch_size, 1, 28, 28).data), 'output/fake')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How one image is factorized through the hidden variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sample = 4\n",
    "kth = 18\n",
    "d = images[kth:kth+1]\n",
    "\n",
    "V = torch.sigmoid(F.linear(d.view(1, -1), model.W, model.h))\n",
    "v, o = torch.sort(V.view(-1))\n",
    "\n",
    "fig, ax = plt.subplots(1, n_sample + 1, figsize=(3*(1 + n_sample),3))\n",
    "ax[0].imshow(d.view(28, 28).numpy(), cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "\n",
    "for k, i in enumerate(o[-n_sample:].numpy()):\n",
    "    f = model.W[i].view(28, 28).data.numpy()\n",
    "    ax[k + 1].imshow(f, cmap='gray')\n",
    "    ax[k + 1].set_title('p=%.2f'% V[0][i].item())\n",
    "    \n",
    "plt.savefig('output/factor.png', dpi=200)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
